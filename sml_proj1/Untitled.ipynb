{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[1]\tvalid_0's auc: 0.886975\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\tvalid_0's auc: 0.891421\n",
      "[3]\tvalid_0's auc: 0.893803\n",
      "[4]\tvalid_0's auc: 0.893765\n",
      "[5]\tvalid_0's auc: 0.893944\n",
      "[6]\tvalid_0's auc: 0.893941\n",
      "[7]\tvalid_0's auc: 0.893789\n",
      "[8]\tvalid_0's auc: 0.897337\n",
      "[9]\tvalid_0's auc: 0.897373\n",
      "[10]\tvalid_0's auc: 0.897381\n",
      "[11]\tvalid_0's auc: 0.897251\n",
      "[12]\tvalid_0's auc: 0.897333\n",
      "[13]\tvalid_0's auc: 0.897352\n",
      "[14]\tvalid_0's auc: 0.897351\n",
      "[15]\tvalid_0's auc: 0.897351\n",
      "[16]\tvalid_0's auc: 0.897749\n",
      "[17]\tvalid_0's auc: 0.897759\n",
      "[18]\tvalid_0's auc: 0.898524\n",
      "[19]\tvalid_0's auc: 0.898624\n",
      "[20]\tvalid_0's auc: 0.898586\n",
      "[21]\tvalid_0's auc: 0.898591\n",
      "[22]\tvalid_0's auc: 0.898898\n",
      "[23]\tvalid_0's auc: 0.898875\n",
      "[24]\tvalid_0's auc: 0.898874\n",
      "[25]\tvalid_0's auc: 0.899008\n",
      "[26]\tvalid_0's auc: 0.89917\n",
      "[27]\tvalid_0's auc: 0.89922\n",
      "[28]\tvalid_0's auc: 0.899236\n",
      "[29]\tvalid_0's auc: 0.899395\n",
      "[30]\tvalid_0's auc: 0.899757\n",
      "[31]\tvalid_0's auc: 0.899781\n",
      "[32]\tvalid_0's auc: 0.899807\n",
      "[33]\tvalid_0's auc: 0.899819\n",
      "[34]\tvalid_0's auc: 0.899879\n",
      "[35]\tvalid_0's auc: 0.902589\n",
      "[36]\tvalid_0's auc: 0.901893\n",
      "[37]\tvalid_0's auc: 0.901991\n",
      "[38]\tvalid_0's auc: 0.901995\n",
      "[39]\tvalid_0's auc: 0.901992\n",
      "[40]\tvalid_0's auc: 0.902053\n",
      "[41]\tvalid_0's auc: 0.902128\n",
      "[42]\tvalid_0's auc: 0.902148\n",
      "[43]\tvalid_0's auc: 0.902245\n",
      "[44]\tvalid_0's auc: 0.902245\n",
      "[45]\tvalid_0's auc: 0.902302\n",
      "[46]\tvalid_0's auc: 0.902368\n",
      "[47]\tvalid_0's auc: 0.902758\n",
      "[48]\tvalid_0's auc: 0.902764\n",
      "[49]\tvalid_0's auc: 0.902808\n",
      "[50]\tvalid_0's auc: 0.902826\n",
      "[51]\tvalid_0's auc: 0.902848\n",
      "[52]\tvalid_0's auc: 0.902882\n",
      "[53]\tvalid_0's auc: 0.903032\n",
      "[54]\tvalid_0's auc: 0.903072\n",
      "[55]\tvalid_0's auc: 0.903096\n",
      "[56]\tvalid_0's auc: 0.903108\n",
      "[57]\tvalid_0's auc: 0.903104\n",
      "[58]\tvalid_0's auc: 0.903125\n",
      "[59]\tvalid_0's auc: 0.90313\n",
      "[60]\tvalid_0's auc: 0.90315\n",
      "[61]\tvalid_0's auc: 0.903207\n",
      "[62]\tvalid_0's auc: 0.913478\n",
      "[63]\tvalid_0's auc: 0.91349\n",
      "[64]\tvalid_0's auc: 0.913473\n",
      "[65]\tvalid_0's auc: 0.913492\n",
      "[66]\tvalid_0's auc: 0.913523\n",
      "[67]\tvalid_0's auc: 0.913525\n",
      "[68]\tvalid_0's auc: 0.913568\n",
      "[69]\tvalid_0's auc: 0.913898\n",
      "[70]\tvalid_0's auc: 0.913906\n",
      "[71]\tvalid_0's auc: 0.913933\n",
      "[72]\tvalid_0's auc: 0.914313\n",
      "[73]\tvalid_0's auc: 0.914344\n",
      "[74]\tvalid_0's auc: 0.914373\n",
      "[75]\tvalid_0's auc: 0.9144\n",
      "[76]\tvalid_0's auc: 0.91439\n",
      "[77]\tvalid_0's auc: 0.91442\n",
      "[78]\tvalid_0's auc: 0.914459\n",
      "[79]\tvalid_0's auc: 0.914485\n",
      "[80]\tvalid_0's auc: 0.914501\n",
      "[81]\tvalid_0's auc: 0.914534\n",
      "[82]\tvalid_0's auc: 0.914601\n",
      "[83]\tvalid_0's auc: 0.914748\n",
      "[84]\tvalid_0's auc: 0.914794\n",
      "[85]\tvalid_0's auc: 0.914811\n",
      "[86]\tvalid_0's auc: 0.914831\n",
      "[87]\tvalid_0's auc: 0.914847\n",
      "[88]\tvalid_0's auc: 0.914857\n",
      "[89]\tvalid_0's auc: 0.914878\n",
      "[90]\tvalid_0's auc: 0.914893\n",
      "[91]\tvalid_0's auc: 0.914904\n",
      "[92]\tvalid_0's auc: 0.914939\n",
      "[93]\tvalid_0's auc: 0.914947\n",
      "[94]\tvalid_0's auc: 0.915663\n",
      "[95]\tvalid_0's auc: 0.91567\n",
      "[96]\tvalid_0's auc: 0.915689\n",
      "[97]\tvalid_0's auc: 0.915717\n",
      "[98]\tvalid_0's auc: 0.915725\n",
      "[99]\tvalid_0's auc: 0.916441\n",
      "[100]\tvalid_0's auc: 0.916451\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's auc: 0.916451\n",
      "Save model...\n",
      "Start predicting...\n",
      "[0.86685916 0.92882995 0.86685916 ... 0.86685916 0.86685916 0.84677592]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "train = pd.read_csv(\"train_set.csv\")\n",
    "test = pd.read_csv(\"test_set.csv\")\n",
    "\n",
    "#y_train = train.exist.values\n",
    "y_train = train['exist'].values\n",
    "\n",
    "\n",
    "train.drop(['exist','source','target'],axis=1)\n",
    "test.drop(['source','target'],axis=1)\n",
    "#X_train = train.values\n",
    "X_train = train.drop(['exist','source','target'],axis=1)\n",
    "#X_test = test.values\n",
    "x_test =test.drop(['source','target'],axis=1)\n",
    "X_train,X_dev,y_train,y_dev = train_test_split(X_train,y_train,test_size=0.3, random_state=200)\n",
    "lgb_train = lgb.Dataset(X_train,y_train)\n",
    "lgb_eval = lgb.Dataset(X_dev,y_dev,reference=lgb_train)\n",
    "\n",
    "\n",
    "# params = {\n",
    "#     'task': 'train',\n",
    "#     'boosting_type': 'gbdt',  # GBDT算法为基础\n",
    "#     'objective': 'binary',  # 因为要完成预测用户是否买单行为，所以是binary，不买是0，购买是1\n",
    "#     'metric': 'auc',  # 评判指标\n",
    "#     'max_bin': 255,  # 大会有更准的效果,更慢的速度\n",
    "#     'learning_rate': 0.02,  # 学习率\n",
    "#     'num_leaves': 64,  # 大会更准,但可能过拟合\n",
    "#     'max_depth': 2,  # 小数据集下限制最大深度可防止过拟合,小于0表示无限制\n",
    "#     'feature_fraction': 0.8,  # 防止过拟合\n",
    "#     'bagging_freq': 5,  # 防止过拟合\n",
    "#     'bagging_fraction': 0.8,  # 防止过拟合\n",
    "#     'min_data_in_leaf': 21,  # 防止过拟合\n",
    "#     'min_sum_hessian_in_leaf': 3.0,  # 防止过拟合\n",
    "#     'header': True  # 数据集是否带表头\n",
    "# }\n",
    "params = {\n",
    "            'objective': 'binary',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'nthread': 4,\n",
    "            'learning_rate': 0.02,  # 02,\n",
    "            'num_leaves': 20,\n",
    "            'colsample_bytree': 0.9497036,\n",
    "            'subsample': 0.8715623,\n",
    "            'subsample_freq': 1,\n",
    "            'max_depth': 2,\n",
    "            'reg_alpha': 0.041545473,\n",
    "            'reg_lambda': 0.0735294,\n",
    "            'min_split_gain': 0.0222415,\n",
    "            'min_child_weight': 60, # 39.3259775,\n",
    "            'seed': 0,\n",
    "            'verbose': -1,\n",
    "            'metric': 'auc',\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=100,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=20)\n",
    "\n",
    "print('Save model...')\n",
    "# save model to file\n",
    "gbm.save_model('model.txt')\n",
    "\n",
    "print('Start predicting...')\n",
    "\n",
    "y_pred = gbm.predict(X_test)\n",
    "print(y_pred)\n",
    "#X_test[['source', 'target']].to_csv(\"submission.csv\", index= False)\n",
    "submission = pd.read_csv(\"sample.csv\")\n",
    "ids = submission['Id'].values\n",
    "#submission.drop('id', inplace=True, axis=1)\n",
    "\n",
    "\n",
    "#x = submission.values\n",
    "#y = model.predict(x)\n",
    "\n",
    "output = pd.DataFrame({'id': ids, 'Prediction': y_pred})\n",
    "#output.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"sample.csv\")\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
